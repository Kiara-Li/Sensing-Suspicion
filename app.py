import streamlit as st
import torch
import numpy as np
import pandas as pd
import plotly.express as px
from transformers import AutoTokenizer, AutoModelForSequenceClassification  # <--- æ”¹ç”¨ Auto ç³»åˆ—
import re

# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="Sensing Suspicion", 
    page_icon="ðŸ•µï¸â€â™€ï¸", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

@st.cache_resource
def load_model():
    # hugging face model ID
    model_path = "KiaraLi2025/creepy-roberta" 
    
    st.write(f"Loading model from Hugging Face: {model_path} ...") 
    
    try:
        # ä½¿ç”¨ AutoTokenizer å’Œ AutoModelï¼Œå®ƒä»¬å®¹é”™çŽ‡æ›´é«˜ï¼Œèƒ½è‡ªåŠ¨é€‚é…
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        return tokenizer, model
    except Exception as e:
        st.error(f"Model loading failed!\nError message: {e}")
        return None, None

def get_prediction_score(text, tokenizer, model):
    """è¿”å›ž 'Creepy' (Label 1) çš„æ¦‚çŽ‡ (0.0 - 1.0)"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    return probs[0][1].item()

def split_into_segments(text):
    """ç®€å•çš„åˆ†å¥é€»è¾‘"""
    # æŒ‰ . ! ? ä»¥åŠæ¢è¡Œç¬¦åˆ‡åˆ†
    segments = re.split(r'(?<=[.!?\n])\s+', text)
    return [s.strip() for s in segments if len(s) > 5] # è¿‡æ»¤æŽ‰å¤ªçŸ­çš„

# --- ç•Œé¢é€»è¾‘ ---

# åŠ è½½æ¨¡åž‹
tokenizer, model = load_model()

st.title("ðŸ•µï¸â€â™€ï¸ Sensing Suspicion")
st.markdown("### A Neural Network for Detecting 'Creepy Signals'")

with st.sidebar:
    st.write("### About This Project")
    st.info(
        "This project aims to use **RoBERTa** to detect subtle *creepy signals* in everyday narratives. "
        "By training the model on Reddit posts from subreddits such as **r/LetsNotMeet** and "
        "**r/TwoSentenceHorror**, it learns linguistic patterns associated with unsafe or suspicious "
        "situations, allowing us to predict whether new text may indicate a potentially dangerous encounter."
    )
    st.write("---")
    st.write("**Accuracy:** 95.2%")
    st.write("**Status:** Trained & Ready")

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ðŸ“ Input Narrative")
    user_input = st.text_area(
        "Paste a story here to analyze...", 
        height=400, 
        placeholder="It was late at night, and I was walking home alone..."
    )
    
    analyze_btn = st.button("ðŸ” Analyze for Suspicion", type="primary")

if analyze_btn and user_input: # åªè¦æœ‰è¾“å…¥å°±å°è¯•è¿è¡Œï¼Œæ¨¡åž‹åŠ è½½å¤±è´¥ä¼šåœ¨ä¸Šé¢æŠ¥é”™
    if tokenizer is None or model is None:
        st.error("æ— æ³•è¿è¡Œåˆ†æžï¼Œå› ä¸ºæ¨¡åž‹æœªèƒ½æˆåŠŸåŠ è½½ã€‚")
    else:
        # 1. å…¨å±€åˆ†æž
        global_score = get_prediction_score(user_input, tokenizer, model)
        
        # 2. é€å¥åˆ†æž (ç”¨äºŽå¼ åŠ›å¼§)
        segments = split_into_segments(user_input)
        segment_scores = []
        
        # è¿›åº¦æ¡
        progress_bar = st.progress(0)
        for i, seg in enumerate(segments):
            score = get_prediction_score(seg, tokenizer, model)
            segment_scores.append(score)
            progress_bar.progress((i + 1) / len(segments))
        progress_bar.empty()

        # --- å³ä¾§ç»“æžœå±•ç¤º ---
        with col2:
            st.subheader("ðŸ“Š Analysis Results")
            
            # ä»ªè¡¨ç›˜
            score_color = "red" if global_score > 0.7 else "orange" if global_score > 0.4 else "green"
            st.markdown(
                f"""
                <div style="text-align: center; margin-bottom: 20px;">
                    <h1 style="color:{score_color}; font-size: 60px; margin:0;">{global_score:.1%}</h1>
                    <p>Creepy Index (Overall)</p>
                </div>
                """, 
                unsafe_allow_html=True
            )

            if global_score > 0.7:
                st.error("âš ï¸ **High Suspicion Detected!** The model flagged significant unsafe patterns.")
            elif global_score > 0.4:
                st.warning("ðŸ¤” **Unsettling Tone.** Some parts of the story feel suspicious.")
            else:
                st.success("âœ… **Safe Narrative.** This reads like a normal everyday story.")

            st.divider()

            # å¼ åŠ›å¼§å¯è§†åŒ–
            st.markdown("#### ðŸ“ˆ Narrative Tension Arc")
            if len(segments) > 0:
                chart_data = pd.DataFrame({
                    'Segment': range(1, len(segments) + 1),
                    'Creepy Score': segment_scores,
                    'Text': [s[:50] + "..." for s in segments] # ç¼©ç•¥æ–‡æœ¬
                })
                
                fig = px.line(chart_data, x='Segment', y='Creepy Score', 
                            markers=True, 
                            hover_data=['Text'],
                            line_shape='spline') # å¹³æ»‘æ›²çº¿
                
                # çº¢è‰²è­¦æˆ’åŒº
                fig.add_hrect(y0=0.8, y1=1.0, line_width=0, fillcolor="red", opacity=0.1)
                fig.update_yaxes(range=[0, 1.05])
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("Text too short for arc analysis.")

        # --- åº•éƒ¨ï¼šé«˜äº®æ–‡æœ¬å±•ç¤º ---
        st.divider()
        st.subheader("ðŸ”¦ Contextual Highlighter")
        st.caption("Sentences flagged as 'Creepy' (>70%) are highlighted in red.")

        annotated_text = ""
        for seg, score in zip(segments, segment_scores):
            if score > 0.7:
                # çº¢è‰²é«˜äº®
                annotated_text += f'<span style="background-color: #ffcccc; padding: 2px 5px; border-radius: 5px; border: 1px solid #ff0000;">{seg}</span> '
            elif score > 0.4:
                # é»„è‰²é«˜äº®
                annotated_text += f'<span style="background-color: #fff4cc; padding: 2px 5px; border-radius: 5px;">{seg}</span> '
            else:
                annotated_text += f'{seg} '
                
        st.markdown(f'<div style="line-height: 1.6;">{annotated_text}</div>', unsafe_allow_html=True)

elif analyze_btn and not user_input:
    st.warning("Please paste some text first!")